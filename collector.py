#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BioFoodLab ì‹ì•½ì²˜ ì¸í—ˆê°€ ë°ì´í„° ìˆ˜ì§‘ê¸° (Firestore ë²„ì „)
- ë§¤ì¼ ìƒˆë²½ 3ì‹œ(KST) cron ì‹¤í–‰
- 16ê°œ APIì—ì„œ ì „êµ­ ë°ì´í„° ìˆ˜ì§‘ â†’ Firestore ì €ì¥
- ì£¼ì†Œ íŒŒì‹±ìœ¼ë¡œ ì‹œë„/ì‹œêµ°êµ¬/ìë©´ë™ ì¸ë±ì‹±
- ë¬´ë£Œ í‹°ì–´ ì“°ê¸° ì œí•œ ì¤€ìˆ˜ (18,000ê±´/ì¼)

ì‚¬ìš©ë²•:
  python3 collector.py              # ì¦ë¶„ ìˆ˜ì§‘ (ì–´ì œ ë³€ê²½ë¶„ë§Œ)
  python3 collector.py --full       # ì „ì²´ ìˆ˜ì§‘ (ìµœì´ˆ ì‹¤í–‰ ì‹œ)
  python3 collector.py --full I1220 # íŠ¹ì • APIë§Œ ì „ì²´ ìˆ˜ì§‘
  python3 collector.py --resume     # ì´ì–´ì„œ ìˆ˜ì§‘ (ì¤‘ë‹¨ëœ ì§€ì ë¶€í„°)
  python3 collector.py --auto       # ìë™ ëª¨ë“œ (ë¯¸ì™„ë£Œâ†’ì´ì–´ì„œ, ì™„ë£Œâ†’ì¦ë¶„) â˜… cronìš©
  python3 collector.py --status     # ìˆ˜ì§‘ í˜„í™© í™•ì¸
"""

import os
import sys
import json
import time
import re
import logging
import argparse
from datetime import datetime, timedelta
from urllib.request import urlopen, Request
from urllib.parse import quote
from urllib.error import URLError, HTTPError

import firebase_admin
from firebase_admin import credentials, firestore

# ============================================================
# ì„¤ì •
# ============================================================

SERVICE_ACCOUNT_KEY = os.path.join(
    os.path.dirname(os.path.abspath(__file__)), 'serviceAccountKey.json'
)

API_KEY = os.environ.get('FSS_API_KEY', 'e5a1d9f07d6c4424a757')
BASE_URL = 'https://openapi.foodsafetykorea.go.kr/api'
BATCH_SIZE = 100  # API 1íšŒ ìš”ì²­ë‹¹ ìµœëŒ€ ê±´ìˆ˜
REQUEST_DELAY = 0.3  # API ìš”ì²­ ê°„ê²©(ì´ˆ) - ì„œë²„ ë¶€í•˜ ë°©ì§€

# Firestore ë¬´ë£Œ í‹°ì–´ ì“°ê¸° ì œí•œ
DAILY_WRITE_LIMIT = 18000  # 20,000 ì¤‘ ì—¬ìœ  2,000

# ============================================================
# API ì •ì˜
# ============================================================

BUSINESS_APIS = {
    'I1220':  {'name': 'ì‹í’ˆì œì¡°ê°€ê³µì—…',              'collection': 'fss_businesses'},
    'I2829':  {'name': 'ì¦‰ì„íŒë§¤ì œì¡°ê°€ê³µì—…',          'collection': 'fss_businesses'},
    'I-0020': {'name': 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì „ë¬¸/ë²¤ì²˜ì œì¡°ì—…', 'collection': 'fss_businesses'},
    'I1300':  {'name': 'ì¶•ì‚°ë¬¼ ê°€ê³µì—…',               'collection': 'fss_businesses'},
    'I1320':  {'name': 'ì¶•ì‚°ë¬¼ ì‹ìœ¡í¬ì¥ì²˜ë¦¬ì—…',       'collection': 'fss_businesses'},
    'I2835':  {'name': 'ì‹ìœ¡ì¦‰ì„íŒë§¤ê°€ê³µì—…',          'collection': 'fss_businesses'},
    'I2831':  {'name': 'ì‹í’ˆì†Œë¶„ì—…',                  'collection': 'fss_businesses'},
    'C001':   {'name': 'ìˆ˜ì…ì‹í’ˆë“±ì˜ì—…ì‹ ê³ ',          'collection': 'fss_businesses'},
    'I1260':  {'name': 'ì‹í’ˆë“±ìˆ˜ì…íŒë§¤ì—…',            'collection': 'fss_businesses'},
}

PRODUCT_APIS = {
    'I1250':  {'name': 'ì‹í’ˆ(ì²¨ê°€ë¬¼)í’ˆëª©ì œì¡°ë³´ê³ ',    'collection': 'fss_products'},
    'I1310':  {'name': 'ì¶•ì‚°ë¬¼ í’ˆëª©ì œì¡°ì •ë³´',         'collection': 'fss_products'},
}

MATERIAL_APIS = {
    'C002':   {'name': 'ì‹í’ˆ(ì²¨ê°€ë¬¼)í’ˆëª©ì œì¡°ë³´ê³ (ì›ì¬ë£Œ)', 'collection': 'fss_materials'},
    'C003':   {'name': 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ í’ˆëª©ì œì¡°ì‹ ê³ (ì›ì¬ë£Œ)', 'collection': 'fss_materials'},
    'C006':   {'name': 'ì¶•ì‚°ë¬¼í’ˆëª©ì œì¡°ë³´ê³ (ì›ì¬ë£Œ)',       'collection': 'fss_materials'},
}

CHANGE_APIS = {
    'I2859':  {'name': 'ì‹í’ˆì—…ì†Œ ì¸í—ˆê°€ ë³€ê²½ ì •ë³´',         'collection': 'fss_changes'},
    'I2860':  {'name': 'ê±´ê°•ê¸°ëŠ¥ì‹í’ˆì—…ì†Œ ì¸í—ˆê°€ ë³€ê²½ ì •ë³´', 'collection': 'fss_changes'},
}

ALL_APIS = {**BUSINESS_APIS, **PRODUCT_APIS, **MATERIAL_APIS, **CHANGE_APIS}

# ============================================================
# ë¡œê¹… ì„¤ì •
# ============================================================

LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'logs')
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(
            os.path.join(LOG_DIR, f'collect_{datetime.now().strftime("%Y%m%d")}.log'),
            encoding='utf-8'
        ),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# Firestore ì´ˆê¸°í™”
# ============================================================

fdb = None

def init_firestore():
    global fdb
    if not os.path.exists(SERVICE_ACCOUNT_KEY):
        logger.error(f'ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {SERVICE_ACCOUNT_KEY}')
        sys.exit(1)

    cred = credentials.Certificate(SERVICE_ACCOUNT_KEY)
    firebase_admin.initialize_app(cred)
    fdb = firestore.client()
    logger.info('Firestore ì—°ê²° ì„±ê³µ')

# ============================================================
# ì£¼ì†Œ íŒŒì‹±
# ============================================================

def parse_address(addr):
    """ì£¼ì†Œ ë¬¸ìì—´ì—ì„œ ì‹œë„/ì‹œêµ°êµ¬/ìë©´ë™ ì¶”ì¶œ"""
    if not addr:
        return None, None, None

    addr = addr.strip()
    parts = addr.split()
    if not parts:
        return None, None, None

    sido = parts[0]
    sigungu = parts[1] if len(parts) > 1 else None
    dong = None

    if len(parts) > 2:
        p2 = parts[2]
        if re.search(r'(ì|ë©´|ë™|ë¦¬|ê°€)$', p2):
            dong = p2

    return sido, sigungu, dong

# ============================================================
# API í˜¸ì¶œ
# ============================================================

_quota_exceeded = False

def fetch_api(service_id, start, end, chng_dt=None):
    """ì‹ì•½ì²˜ API í˜¸ì¶œ â†’ JSON íŒŒì‹±"""
    global _quota_exceeded

    if _quota_exceeded:
        return 0, [], 'quota_exceeded'

    url = f'{BASE_URL}/{API_KEY}/{service_id}/json/{start}/{end}'
    if chng_dt:
        url += f'/CHNG_DT={chng_dt}'

    try:
        req = Request(url, headers={'User-Agent': 'BioFoodLab-Collector/1.0'})
        with urlopen(req, timeout=30) as resp:
            raw = resp.read()

        if not raw or len(raw) == 0:
            logger.warning(f'  ë¹ˆ ì‘ë‹µ ({service_id} {start}-{end}), url={url}')
            return 0, [], 'error'

        text = raw.decode('utf-8', errors='replace')
        text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', text)

        data = json.loads(text)
        key = list(data.keys())[0]
        result = data[key]

        if 'RESULT' in result:
            code = result['RESULT'].get('CODE', '')
            msg = result['RESULT'].get('MSG', '')

            if code == 'INFO-300':
                logger.warning(f'  API í˜¸ì¶œ í•œë„ ì´ˆê³¼! ({msg})')
                _quota_exceeded = True
                return 0, [], 'quota_exceeded'

            if code == 'INFO-200':
                return 0, [], 'empty'

            if code.startswith('ERROR'):
                logger.warning(f'  API ì˜¤ë¥˜ ({service_id}): [{code}] {msg}')
                return 0, [], 'error'

        tc = result.get('total_count', 0)
        total = int(tc) if tc != '' and tc is not None else 0

        rows = result.get('row', [])
        return total, rows, 'ok'

    except (json.JSONDecodeError, KeyError) as e:
        logger.warning(f'  JSON íŒŒì‹± ì˜¤ë¥˜ ({service_id} {start}-{end}): {e}')
        return 0, [], 'error'
    except (URLError, HTTPError, TimeoutError) as e:
        logger.warning(f'  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ({service_id} {start}-{end}): {e}')
        return 0, [], 'error'
    except Exception as e:
        logger.error(f'  ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ({service_id} {start}-{end}): {e}')
        return 0, [], 'error'

# ============================================================
# Firestore ì €ì¥
# ============================================================

_daily_write_count = 0

def check_write_quota():
    """ë¬´ë£Œ í‹°ì–´ ì“°ê¸° í•œë„ ì²´í¬"""
    global _daily_write_count
    if _daily_write_count >= DAILY_WRITE_LIMIT:
        logger.warning(f'ì¼ì¼ ì“°ê¸° í•œë„ ë„ë‹¬ ({DAILY_WRITE_LIMIT}ê±´). ìˆ˜ì§‘ ì¤‘ë‹¨.')
        return False
    return True


def upsert_business(batch, api_source, row):
    """ì—…ì†Œ ì¸í—ˆê°€ Firestore ì €ì¥"""
    global _daily_write_count
    if not check_write_quota():
        return 'quota_exceeded'

    lcns_no = row.get('LCNS_NO', '')
    if not lcns_no:
        return 0

    addr = row.get('LOCP_ADDR', '')
    sido, sigungu, dong = parse_address(addr)

    doc_ref = fdb.collection('fss_businesses').document(lcns_no)
    batch.set(doc_ref, {
        'api_source': api_source,
        'lcns_no': lcns_no,
        'bssh_nm': row.get('BSSH_NM', ''),
        'prsdnt_nm': row.get('PRSDNT_NM') or '',
        'induty_nm': row.get('INDUTY_NM') or '',
        'prms_dt': row.get('PRMS_DT') or '',
        'telno': row.get('TELNO') or '',
        'locp_addr': addr,
        'instt_nm': row.get('INSTT_NM') or '',
        'clsbiz_dvs_nm': row.get('CLSBIZ_DVS_NM') or '',
        'addr_sido': sido or '',
        'addr_sigungu': sigungu or '',
        'addr_dong': dong or '',
        'collected_at': firestore.SERVER_TIMESTAMP,
    }, merge=True)
    _daily_write_count += 1
    return 1


def upsert_product(batch, api_source, row):
    """í’ˆëª© ì œì¡° ë³´ê³  Firestore ì €ì¥"""
    global _daily_write_count
    if not check_write_quota():
        return 'quota_exceeded'

    report_no = row.get('PRDLST_REPORT_NO', '')
    if not report_no:
        return 0

    doc_ref = fdb.collection('fss_products').document(report_no)
    batch.set(doc_ref, {
        'api_source': api_source,
        'lcns_no': row.get('LCNS_NO', ''),
        'bssh_nm': row.get('BSSH_NM') or '',
        'prdlst_report_no': report_no,
        'prms_dt': row.get('PRMS_DT') or '',
        'prdlst_nm': row.get('PRDLST_NM') or '',
        'prdlst_dcnm': row.get('PRDLST_DCNM') or '',
        'production': row.get('PRODUCTION') or '',
        'hieng_lntrt_dvs_nm': row.get('HIENG_LNTRT_DVS_NM') or '',
        'child_crtfc_yn': row.get('CHILD_CRTFC_YN') or '',
        'pog_daycnt': row.get('POG_DAYCNT') or '',
        'induty_cd_nm': row.get('INDUTY_CD_NM') or '',
        'dispos': row.get('DISPOS') or '',
        'shap': row.get('SHAP') or '',
        'stdr_stnd': row.get('STDR_STND') or '',
        'ntk_mthd': row.get('NTK_MTHD') or '',
        'primary_fnclty': row.get('PRIMARY_FNCLTY') or '',
        'iftkn_atnt_matr_cn': row.get('IFTKN_ATNT_MATR_CN') or '',
        'cstdy_mthd': row.get('CSTDY_MTHD') or '',
        'prdt_shap_cd_nm': row.get('PRDT_SHAP_CD_NM') or '',
        'usage_info': row.get('USAGE') or '',
        'prpos': row.get('PRPOS') or '',
        'frmlc_mtrqlt': row.get('FRMLC_MTRQLT') or '',
        'qlity_mntnc': row.get('QLITY_MNTNC_TMLMT_DAYCNT') or '',
        'etqty_xport': row.get('ETQTY_XPORT_PRDLST_YN') or '',
        'last_updt_dtm': row.get('LAST_UPDT_DTM') or '',
        'collected_at': firestore.SERVER_TIMESTAMP,
    }, merge=True)
    _daily_write_count += 1
    return 1


def upsert_material(batch, api_source, row):
    """ì›ì¬ë£Œ ì •ë³´ Firestore ì €ì¥"""
    global _daily_write_count
    if not check_write_quota():
        return 'quota_exceeded'

    report_no = row.get('PRDLST_REPORT_NO', '')
    ordno = str(row.get('RAWMTRL_ORDNO', '0'))
    if not report_no:
        return 0

    doc_id = f'{report_no}_{ordno}'
    doc_ref = fdb.collection('fss_materials').document(doc_id)
    batch.set(doc_ref, {
        'api_source': api_source,
        'lcns_no': row.get('LCNS_NO') or '',
        'bssh_nm': row.get('BSSH_NM') or '',
        'prdlst_report_no': report_no,
        'prms_dt': row.get('PRMS_DT') or '',
        'prdlst_nm': row.get('PRDLST_NM') or '',
        'prdlst_dcnm': row.get('PRDLST_DCNM') or '',
        'rawmtrl_nm': row.get('RAWMTRL_NM') or '',
        'rawmtrl_ordno': ordno,
        'chng_dt': row.get('CHNG_DT') or '',
        'etqty_xport': row.get('ETQTY_XPORT_PRDLST_YN') or '',
        'collected_at': firestore.SERVER_TIMESTAMP,
    }, merge=True)
    _daily_write_count += 1
    return 1


def insert_change(batch, api_source, row):
    """ë³€ê²½ ì´ë ¥ Firestore ì €ì¥ (ìë™ ID)"""
    global _daily_write_count
    if not check_write_quota():
        return 'quota_exceeded'

    doc_ref = fdb.collection('fss_changes').document()
    batch.set(doc_ref, {
        'api_source': api_source,
        'lcns_no': row.get('LCNS_NO', ''),
        'bssh_nm': row.get('BSSH_NM') or '',
        'induty_cd_nm': row.get('INDUTY_CD_NM') or '',
        'telno': row.get('TELNO') or '',
        'site_addr': row.get('SITE_ADDR') or '',
        'chng_dt': row.get('CHNG_DT') or '',
        'chng_bf_cn': row.get('CHNG_BF_CN') or '',
        'chng_af_cn': row.get('CHNG_AF_CN') or '',
        'chng_prvns': row.get('CHNG_PRVNS') or '',
        'collected_at': firestore.SERVER_TIMESTAMP,
    })
    _daily_write_count += 1
    return 1

# ============================================================
# Firestoreì—ì„œ ê¸°ì¡´ ìˆ˜ì§‘ ê±´ìˆ˜ í™•ì¸
# ============================================================

def get_collected_count(service_id, collection_name):
    """í•´ë‹¹ APIì˜ Firestore ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
    try:
        query = fdb.collection(collection_name).where('api_source', '==', service_id)
        # count() ì§‘ê³„ ì‚¬ìš© (Firestore v2)
        count_query = query.count()
        results = count_query.get()
        return results[0][0].value if results else 0
    except Exception:
        # count()ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° fallback
        try:
            docs = fdb.collection(collection_name).where('api_source', '==', service_id).select([]).stream()
            return sum(1 for _ in docs)
        except Exception:
            return 0

# ============================================================
# ìˆ˜ì§‘ ë¡œê·¸ ê¸°ë¡
# ============================================================

def log_collection(api_source, api_name, collect_type,
                   total, fetched, inserted, updated, errors, error_msg, started_at):
    """ìˆ˜ì§‘ ë¡œê·¸ë¥¼ Firestoreì— ê¸°ë¡"""
    finished_at = datetime.now()
    duration = int((finished_at - started_at).total_seconds())
    try:
        fdb.collection('fss_collect_log').add({
            'api_source': api_source,
            'api_name': api_name,
            'collect_type': collect_type,
            'total_count': total,
            'fetched_count': fetched,
            'inserted_count': inserted,
            'updated_count': updated,
            'error_count': errors,
            'error_msg': error_msg or '',
            'started_at': started_at.isoformat(),
            'finished_at': finished_at.isoformat(),
            'duration_sec': duration,
        })
    except Exception as e:
        logger.error(f'ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}')


def update_data_counts():
    """Firestore fss_config/data_counts ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (í”„ë¡ íŠ¸ì—”ë“œìš©)"""
    try:
        counts = {}
        totals = {}
        for col_name in ['fss_businesses', 'fss_products', 'fss_materials', 'fss_changes']:
            docs = fdb.collection(col_name).stream()
            api_counts = {}
            total = 0
            for doc in docs:
                total += 1
                data = doc.to_dict()
                src = data.get('api_source', 'unknown')
                api_counts[src] = api_counts.get(src, 0) + 1
            totals[col_name] = total
            counts.update(api_counts)

        fdb.collection('fss_config').document('data_counts').set({
            'counts': counts,
            'total': totals,
            'updated_at': firestore.SERVER_TIMESTAMP,
        })
        logger.info(f'  ğŸ“Š ì¹´ìš´íŠ¸ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸: {totals}')
    except Exception as e:
        logger.error(f'ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}')


# ============================================================
# ìˆ˜ì§‘ ë©”ì¸ ë¡œì§
# ============================================================

def collect_api(service_id, api_info, collect_type='incremental',
                chng_dt=None, resume=False):
    """ë‹¨ì¼ API ì „ì²´ ìˆ˜ì§‘"""
    global _quota_exceeded, _daily_write_count

    collection_name = api_info['collection']
    name = api_info['name']

    if _quota_exceeded:
        logger.info(f'â­ï¸ [{service_id}] {name} â€” í•œë„ ì´ˆê³¼ë¡œ ê±´ë„ˆëœ€')
        return 'quota_exceeded'

    if not check_write_quota():
        logger.info(f'â­ï¸ [{service_id}] {name} â€” Firestore ì“°ê¸° í•œë„ ë„ë‹¬')
        return 'write_limit'

    started_at = datetime.now()
    logger.info(f'â–¶ [{service_id}] {name} ìˆ˜ì§‘ ì‹œì‘ ({collect_type})')

    # 1ë‹¨ê³„: ì´ ê±´ìˆ˜ í™•ì¸
    dt_param = chng_dt if collect_type == 'incremental' and chng_dt else None
    total, _, status = fetch_api(service_id, 1, 1, dt_param)

    if status == 'quota_exceeded':
        logger.warning(f'  â­ï¸ í•œë„ ì´ˆê³¼ â€” ì´ API ê±´ë„ˆëœ€')
        log_collection(service_id, name, collect_type, 0, 0, 0, 0, 0,
                       'API í˜¸ì¶œ í•œë„ ì´ˆê³¼ (INFO-300)', started_at)
        return 'quota_exceeded'

    if total == 0:
        logger.info(f'  â†’ ë°ì´í„° ì—†ìŒ (0ê±´)')
        log_collection(service_id, name, collect_type, 0, 0, 0, 0, 0, None, started_at)
        return 'empty'

    # resume ëª¨ë“œ: ì´ë¯¸ ìˆ˜ì§‘ëœ ê±´ìˆ˜ í™•ì¸
    start_from = 1
    if resume:
        already = get_collected_count(service_id, collection_name)
        if already >= total:
            logger.info(f'  âœ… ì´ë¯¸ ì™„ë£Œ: Firestore {already:,}ê±´ / API {total:,}ê±´')
            log_collection(service_id, name, collect_type + '_resume',
                           total, 0, 0, 0, 0, 'ì´ë¯¸ ìˆ˜ì§‘ ì™„ë£Œ', started_at)
            return 'already_done'
        elif already > 0:
            start_from = already + 1
            logger.info(f'  ğŸ”„ ì´ì–´ì„œ ìˆ˜ì§‘: Firestore {already:,}ê±´ ë³´ìœ  â†’ {start_from:,}ë²ˆë¶€í„° ì‹œì‘ (ì´ {total:,}ê±´)')
        else:
            logger.info(f'  ì´ {total:,}ê±´ ìˆ˜ì§‘ ì˜ˆì •')
    else:
        logger.info(f'  ì´ {total:,}ê±´ ìˆ˜ì§‘ ì˜ˆì •')

    # 2ë‹¨ê³„: í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìˆ˜ì§‘
    fetched = 0
    inserted = 0
    updated = 0
    errors = 0
    error_msg = None

    try:
        batch = fdb.batch()
        batch_count = 0

        for start in range(start_from, total + 1, BATCH_SIZE):
            end = min(start + BATCH_SIZE - 1, total)
            _, rows, status = fetch_api(service_id, start, end, dt_param)

            if status == 'quota_exceeded':
                logger.warning(f'  âš ï¸ {fetched:,}ê±´ê¹Œì§€ ìˆ˜ì§‘ í›„ API í•œë„ ì´ˆê³¼ë¡œ ì¤‘ë‹¨')
                if batch_count > 0:
                    batch.commit()
                error_msg = f'API í•œë„ ì´ˆê³¼ â€” {start_from}~{start-1}ë²ˆ ìˆ˜ì§‘ ì™„ë£Œ'
                break

            if not rows:
                time.sleep(REQUEST_DELAY)
                continue

            for row in rows:
                # Firestore ì“°ê¸° í•œë„ ì²´í¬
                if not check_write_quota():
                    logger.warning(f'  âš ï¸ Firestore ì“°ê¸° í•œë„ ë„ë‹¬ ({_daily_write_count}ê±´)')
                    if batch_count > 0:
                        batch.commit()
                    error_msg = f'Firestore ì“°ê¸° í•œë„ ë„ë‹¬ â€” {fetched}ê±´ ìˆ˜ì§‘ ì™„ë£Œ'
                    log_collection(service_id, name,
                                   collect_type + ('_resume' if resume else ''),
                                   total, fetched, inserted, updated, errors, error_msg, started_at)
                    return 'write_limit'

                try:
                    if collection_name == 'fss_businesses':
                        rc = upsert_business(batch, service_id, row)
                    elif collection_name == 'fss_products':
                        rc = upsert_product(batch, service_id, row)
                    elif collection_name == 'fss_materials':
                        rc = upsert_material(batch, service_id, row)
                    elif collection_name == 'fss_changes':
                        rc = insert_change(batch, service_id, row)
                    else:
                        continue

                    if rc == 'quota_exceeded':
                        if batch_count > 0:
                            batch.commit()
                        error_msg = f'Firestore ì“°ê¸° í•œë„ â€” {fetched}ê±´ ìˆ˜ì§‘ ì™„ë£Œ'
                        log_collection(service_id, name,
                                       collect_type + ('_resume' if resume else ''),
                                       total, fetched, inserted, updated, errors, error_msg, started_at)
                        return 'write_limit'

                    inserted += 1
                    fetched += 1
                    batch_count += 1

                except Exception as e:
                    errors += 1
                    if errors <= 5:
                        logger.warning(f'  Firestore ì˜¤ë¥˜: {e} / row={row.get("LCNS_NO", "?")}')
                    if not error_msg:
                        error_msg = str(e)

            # ë°°ì¹˜ ì»¤ë°‹ (ìµœëŒ€ 499ê±´)
            if batch_count >= 450:
                batch.commit()
                batch = fdb.batch()
                batch_count = 0

            # ì§„í–‰ë¥  ë¡œê·¸
            total_fetched = (start_from - 1) + fetched if resume else fetched
            if fetched > 0 and fetched % 1000 < BATCH_SIZE:
                pct = (total_fetched / total * 100) if total else 0
                logger.info(f'  ì§„í–‰: {total_fetched:,}/{total:,} ({pct:.1f}%) ì…ë ¥={inserted} (ì“°ê¸°={_daily_write_count})')

            time.sleep(REQUEST_DELAY)

        # ë‚¨ì€ ë°°ì¹˜ ì»¤ë°‹
        if batch_count > 0:
            batch.commit()

    except Exception as e:
        logger.error(f'  ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}')
        error_msg = str(e)

    elapsed = (datetime.now() - started_at).total_seconds()
    result_status = 'quota_exceeded' if _quota_exceeded else 'ok'

    if result_status == 'ok':
        logger.info(f'  âœ… ì™„ë£Œ: {fetched:,}ê±´ (ì…ë ¥={inserted}, ì˜¤ë¥˜={errors}) [{elapsed:.0f}ì´ˆ] (ì¼ì¼ ì“°ê¸°: {_daily_write_count})')
    else:
        logger.info(f'  â¸ï¸ ì¤‘ë‹¨: {fetched:,}ê±´ ì €ì¥ë¨ [{elapsed:.0f}ì´ˆ]')

    log_collection(service_id, name,
                   collect_type + ('_resume' if resume else ''),
                   total, fetched, inserted, updated, errors, error_msg, started_at)

    return result_status


def collect_api_auto(service_id, api_info):
    """ìë™ ëª¨ë“œ: ë¯¸ì™„ë£Œ APIëŠ” ì´ì–´ì„œ ìˆ˜ì§‘, ì™„ë£Œëœ APIëŠ” ì¦ë¶„ ìˆ˜ì§‘"""
    global _quota_exceeded

    if _quota_exceeded:
        logger.info(f'â­ï¸ [{service_id}] {api_info["name"]} â€” í•œë„ ì´ˆê³¼ë¡œ ê±´ë„ˆëœ€')
        return 'quota_exceeded'

    if not check_write_quota():
        logger.info(f'â­ï¸ [{service_id}] {api_info["name"]} â€” Firestore ì“°ê¸° í•œë„ ë„ë‹¬')
        return 'write_limit'

    collection_name = api_info['collection']
    name = api_info['name']

    # 1) API ì´ ê±´ìˆ˜ í™•ì¸
    api_total, _, status = fetch_api(service_id, 1, 1, None)
    if status == 'quota_exceeded':
        return 'quota_exceeded'

    # 2) Firestore ê±´ìˆ˜ í™•ì¸
    db_count = get_collected_count(service_id, collection_name)

    # 2-1) API ì¡°íšŒ ì‹¤íŒ¨ ë°©ì–´: api_total=0ì¸ë° Firestoreì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—ëŸ¬
    if api_total == 0 and status in ('error', 'empty'):
        if db_count > 0:
            logger.warning(f'âš ï¸ [{service_id}] {name}: API ì¡°íšŒ ì‹¤íŒ¨ (status={status}) '
                          f'but Firestore has {db_count:,}ê±´ â€” ê±´ë„ˆë›°ê¸°')
            return 'error'
        else:
            logger.info(f'  â†’ [{service_id}] {name}: ë°ì´í„° ì—†ìŒ (API ë° Firestore ëª¨ë‘ 0ê±´)')
            return 'empty'

    # 3) íŒë‹¨
    if api_total > 0 and db_count < api_total:
        pct = (db_count / api_total * 100) if api_total else 0
        logger.info(f'ğŸ“Š [{service_id}] {name}: Firestore {db_count:,} / API {api_total:,} ({pct:.1f}%) â†’ ì´ì–´ì„œ ìˆ˜ì§‘')
        return collect_api(service_id, api_info,
                          collect_type='full', chng_dt=None, resume=True)
    else:
        week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')
        logger.info(f'âœ… [{service_id}] {name}: Firestore {db_count:,} / API {api_total:,} â€” ì¦ë¶„ ìˆ˜ì§‘ ({week_ago}~)')
        return collect_api(service_id, api_info,
                          collect_type='incremental', chng_dt=week_ago, resume=False)

# ============================================================
# ìˆ˜ì§‘ í˜„í™©
# ============================================================

def show_status():
    """í˜„ì¬ Firestore ìˆ˜ì§‘ í˜„í™© ì¶œë ¥"""
    print('\n' + '=' * 70)
    print('  ì‹ì•½ì²˜ ë°ì´í„° ìˆ˜ì§‘ í˜„í™© (Firestore)')
    print('=' * 70)

    collections = [
        ('fss_businesses', 'ì—…ì†Œ ì¸í—ˆê°€'),
        ('fss_products', 'í’ˆëª© ì œì¡°'),
        ('fss_materials', 'ì›ì¬ë£Œ'),
        ('fss_changes', 'ë³€ê²½ ì´ë ¥'),
    ]
    print(f'\n{"ì»¬ë ‰ì…˜":<20} {"ê±´ìˆ˜":>12}')
    print('-' * 35)
    for col, name in collections:
        try:
            count_query = fdb.collection(col).count()
            results = count_query.get()
            cnt = results[0][0].value if results else 0
            print(f'{name:<20} {cnt:>12,}')
        except Exception:
            try:
                docs = fdb.collection(col).select([]).stream()
                cnt = sum(1 for _ in docs)
                print(f'{name:<20} {cnt:>12,}')
            except Exception:
                print(f'{name:<20} {"(ì˜¤ë¥˜)":>12}')

    # APIë³„ ê±´ìˆ˜
    print(f'\n{"API":<10} {"ì´ë¦„":<25} {"ìƒíƒœ":>8}')
    print('-' * 45)
    for sid, info in ALL_APIS.items():
        cnt = get_collected_count(sid, info['collection'])
        status = 'âœ…' if cnt > 0 else 'â¬œ'
        print(f'{sid:<10} {info["name"]:<25} {cnt:>8,} {status}')

    # ìµœê·¼ ìˆ˜ì§‘ ë¡œê·¸
    print(f'\nìµœê·¼ ìˆ˜ì§‘ ì´ë ¥:')
    print('-' * 70)
    try:
        logs = fdb.collection('fss_collect_log').order_by(
            'started_at', direction=firestore.Query.DESCENDING
        ).limit(10).stream()

        for doc in logs:
            r = doc.to_dict()
            dt = (r.get('started_at', '') or '')[:16]
            err_info = f" âš ï¸{r.get('error_msg', '')[:30]}" if r.get('error_msg') else ''
            print(f"  {dt} [{r.get('api_source', '')}] {r.get('api_name', '')} "
                  f"({r.get('collect_type', '')}) {r.get('fetched_count', 0):,}ê±´ "
                  f"(+{r.get('inserted_count', 0)}/âœ—{r.get('error_count', 0)})"
                  f" {r.get('duration_sec', 0)}ì´ˆ{err_info}")
    except Exception:
        print('  (ë¡œê·¸ ì—†ìŒ)')

    print()

# ============================================================
# ì„¤ì • ë¡œë“œ (Firestoreì—ì„œ)
# ============================================================

def load_schedule_config():
    """Firestoreì—ì„œ ìŠ¤ì¼€ì¤„ ì„¤ì • ì½ê¸°"""
    try:
        doc = fdb.collection('fss_config').document('schedule').get()
        return doc.to_dict() if doc.exists else None
    except Exception:
        return None


def load_api_configs():
    """Firestoreì—ì„œ API ì„¤ì • ì½ê¸°"""
    try:
        docs = fdb.collection('fss_config').document('apis').collection('list').stream()
        rows = [doc.to_dict() for doc in docs]
        return rows if rows else None
    except Exception:
        return None

# ============================================================
# ë©”ì¸
# ============================================================

def main():
    global _quota_exceeded, _daily_write_count

    parser = argparse.ArgumentParser(description='ì‹ì•½ì²˜ ì¸í—ˆê°€ ë°ì´í„° ìˆ˜ì§‘ê¸° (Firestore)')
    parser.add_argument('--full', action='store_true', help='ì „ì²´ ìˆ˜ì§‘ (ìµœì´ˆ ì‹¤í–‰)')
    parser.add_argument('--resume', action='store_true', help='ì´ì–´ì„œ ìˆ˜ì§‘ (ì¤‘ë‹¨ëœ ì§€ì ë¶€í„°)')
    parser.add_argument('--auto', action='store_true', help='ìë™ ëª¨ë“œ (ë¯¸ì™„ë£Œâ†’ì´ì–´ì„œ, ì™„ë£Œâ†’ì¦ë¶„) cronìš©')
    parser.add_argument('--status', action='store_true', help='ìˆ˜ì§‘ í˜„í™© í™•ì¸')
    parser.add_argument('apis', nargs='*', help='íŠ¹ì • APIë§Œ ìˆ˜ì§‘ (ì˜ˆ: I1220 I2829)')
    args = parser.parse_args()

    # Firestore ì´ˆê¸°í™”
    init_firestore()

    try:
        if args.status:
            show_status()
            return

        # Firestoreì—ì„œ ì„¤ì • ì½ê¸°
        db_schedule = load_schedule_config()
        db_api_configs = load_api_configs()

        # ì„¤ì • ì ìš©
        global API_KEY, BATCH_SIZE, REQUEST_DELAY
        if db_schedule:
            if db_schedule.get('api_key'):
                API_KEY = db_schedule['api_key']
            if db_schedule.get('batch_size'):
                BATCH_SIZE = int(db_schedule['batch_size'])
            if db_schedule.get('request_delay'):
                REQUEST_DELAY = float(db_schedule['request_delay'])
            logger.info(f'Firestore ì„¤ì • ë¡œë“œ: batch={BATCH_SIZE}, delay={REQUEST_DELAY}s')

        # ìˆ˜ì§‘ ëª¨ë“œ ê²°ì •
        if args.resume:
            collect_type = 'full'
        elif args.auto:
            collect_type = 'auto'
        else:
            collect_type = 'full' if args.full else (
                db_schedule.get('collect_mode', 'incremental') if db_schedule else 'incremental'
            )

        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
        chng_dt = yesterday if collect_type not in ('full', 'auto') else None

        # ìˆ˜ì§‘ ëŒ€ìƒ ê²°ì •
        if args.apis:
            targets = {k: v for k, v in ALL_APIS.items() if k in args.apis}
            if not targets:
                logger.error(f'ìœ íš¨í•˜ì§€ ì•Šì€ API: {args.apis}')
                logger.info(f'ì‚¬ìš© ê°€ëŠ¥í•œ API: {list(ALL_APIS.keys())}')
                return
        elif db_api_configs:
            enabled_ids = [c['api_source'] for c in db_api_configs if c.get('is_enabled')]
            targets = {k: v for k, v in ALL_APIS.items() if k in enabled_ids}
            if not targets:
                logger.warning('ì„¤ì •ì— í™œì„±í™”ëœ APIê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ APIë¡œ ì§„í–‰í•©ë‹ˆë‹¤.')
                targets = ALL_APIS
            else:
                logger.info(f'Firestore ì„¤ì • ê¸°ì¤€: {len(targets)}ê°œ API í™œì„±')
        else:
            targets = ALL_APIS

        logger.info(f'{"="*60}')
        logger.info(f'ì‹ì•½ì²˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({collect_type}{"+ resume" if args.resume else ""}) [Firestore]')
        logger.info(f'ëŒ€ìƒ: {len(targets)}ê°œ API')
        logger.info(f'ì„¤ì •: batch_size={BATCH_SIZE}, delay={REQUEST_DELAY}s')
        logger.info(f'Firestore ì“°ê¸° í•œë„: {DAILY_WRITE_LIMIT:,}ê±´/ì¼')
        if chng_dt:
            logger.info(f'ë³€ê²½ì¼ì ê¸°ì¤€: {chng_dt} ì´í›„')
        logger.info(f'{"="*60}')

        total_start = time.time()
        _quota_exceeded = False
        _daily_write_count = 0

        # ìˆ˜ì§‘ ìˆœì„œ: ì—…ì†Œ â†’ í’ˆëª© â†’ ì›ì¬ë£Œ â†’ ë³€ê²½ì´ë ¥
        order = list(BUSINESS_APIS.keys()) + list(PRODUCT_APIS.keys()) + \
                list(MATERIAL_APIS.keys()) + list(CHANGE_APIS.keys())

        completed = []
        skipped = []

        for sid in order:
            if sid in targets:
                if collect_type == 'auto':
                    result = collect_api_auto(sid, targets[sid])
                else:
                    result = collect_api(sid, targets[sid], collect_type,
                                         chng_dt, resume=args.resume)
                if result in ('quota_exceeded', 'write_limit'):
                    skipped.append(sid)
                else:
                    completed.append(sid)

        elapsed = time.time() - total_start
        logger.info(f'{"="*60}')
        logger.info(f'ìˆ˜ì§‘ ì¢…ë£Œ! ì´ ì†Œìš”ì‹œê°„: {elapsed:.0f}ì´ˆ ({elapsed/60:.1f}ë¶„)')
        logger.info(f'  ì™„ë£Œ: {len(completed)}ê°œ API {completed}')
        logger.info(f'  Firestore ì“°ê¸°: {_daily_write_count:,}ê±´')
        if skipped:
            logger.info(f'  â­ï¸ ê±´ë„ˆëœ€: {len(skipped)}ê°œ API {skipped}')
            logger.info(f'  â†’ ë‚´ì¼ ìë™ ìˆ˜ì§‘ ì‹œ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤ (--auto)')
        logger.info(f'{"="*60}')

        # í”„ë¡ íŠ¸ì—”ë“œìš© ì¹´ìš´íŠ¸ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if completed:
            update_data_counts()

        show_status()

    except Exception as e:
        logger.error(f'ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}')
        raise


if __name__ == '__main__':
    main()
